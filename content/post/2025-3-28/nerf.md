---
title: "Nerf"
date: 2025-03-23T10:58:52+08:00
draft: false
---

## 渲染与反渲染

![inverse_render](https://zhytou.github.io/post/2025-4-11/inverse_render.png)

反渲染（Inverse Rendering）是计算机视觉和计算机图形学中的一个重要概念，旨在从观察到的图像中推断出场景的三维结构、光照条件和材质属性等信息。通过这些信息，我们可以重建场景的三维模型，或者生成新的视角下的图像。

反渲染的关键点包括：

- 由图像反渲染的得到场景形状（shape）和外观（apperance）如何表示？
- 如何根据这些信息进一步生成新的视角下的图像，即如何再次渲染（render）？

### 形状表征

点云（Point Cloud）：点云是一种稀疏的三维表示方法，由一组离散的点组成，每个点包含其在三维空间中的坐标和其他属性（如颜色、法线等）。点云通常用于表示复杂的三维形状，如扫描得到的物体表面。

网格（Mesh）：网格是一种更为常见的三维表示方法，由顶点、边和面组成。网格可以表示更复杂的形状，并且通常具有更高的渲染效率。网格的每个面通常是一个三角形或四边形，顶点之间通过边连接形成面。

占据场（Occupancy Field）：占据场是一种隐式的三维表示方法，通过一个函数来判断空间中某个点是否被占据。占据场通常用于表示稀疏的三维结构，如室内场景或城市环境。

有符号距离场（Signed Distance Field，SDF）：有符号距离场也是一种隐式的三维表示方法。它通过一个函数来计算空间中某个点到最近表面的距离。SDF可以用于表示复杂的形状，并且在物体重建和碰撞检测等应用中具有很好的性能。

> [3D隐式表示](https://blog.csdn.net/weixin_43117620/article/details/131980822)

### 外观表征

![apperance_representation](https://zhytou.github.io/post/2025-4-11/apperance_representation.png)

## 神经辐射场

> [Representing Scenes as Neural Radiance Fields for View Synthesis](https://arxiv.org/pdf/2003.08934)

神经辐射场（Neural Radiancce Field，Nerf）是一种基于深度学习的3D场景表示与视图合成方法，能够从多视角2D图像中重建出高质量的三维场景，并生成任意视角下的逼真新视图。其核心思想是通过神经网络隐式地建模场景中每个3D点的颜色和密度分布，结合光线追踪技术实现物理真实的渲染效果。

### 场景表示

如前文所述，实现反渲染首先需要通过某种方式表示由图像得到的3D内容。在Nerf中，这一点依靠神经网络模型来实现。具体来说，Nerf使用一个多层感知机（MLP）来表示场景中的每个3D点。该MLP接受一个3D坐标（x, y, z）和一个2D视角方向（θ, φ）作为输入，输出该点在该视角下的颜色（r, g, b）和不透明度（σ）。

### 体渲染

有了反渲染所需的3D内容表示后，Nerf依靠体渲染技术（Volume Rendering）来生成新视角下的图像。在计算机图形学中，体渲染是一类通过对3D体数据进行采样和积分来生成2D图像的方法。区别于传统的表面渲染方法，如光栅化（Rasterization）或光线追踪（Ray Tracing），体渲染主要针对以点云、体素和辐射场之类的体数据表示的场景。它通过对3D空间中的每个点进行采样，计算其颜色和不透明度，并将这些信息结合起来生成最终的2D图像。

**体渲染方程**：

不同表面渲染，体渲染并不使用由吉姆·卡吉雅提出的渲染方程。它使用的是体积渲染方程（Volume Rendering Equation），该方程描述了从3D体数据生成2D图像的过程。体积渲染方程可以表示为：

$$
I(\mathbf{r}) = \int_{t_n}^{t_f} T(t) \sigma(\mathbf{r}(t)) c(\mathbf{r}(t), \mathbf{d}) dt
$$

其中，

**体渲染方程在Nerf中的求解**：

### Nerf的工作流

1. **光线采样**：从相机位置发射光线，沿着光线的方向进行采样。每个采样点对应于3D空间中的一个点。
2. **MLP预测**：对于每个采样点，使用MLP预测其颜色和不透明度。输入为3D坐标和视角方向，输出为颜色（r, g, b）和不透明度（σ）。
3. **体积积分**：根据体积渲染方程，对采样点的颜色和不透明度进行积分，计算最终的像素颜色。积分过程通常使用数值方法，如梯形法则或蒙特卡洛方法。
4. **合成图像**：将所有采样点的颜色和不透明度结合起来，生成最终的2D图像。
5. **损失函数**：通过与真实图像进行比较，计算损失函数（如均方误差），并使用反向传播算法更新MLP的参数。
6. **迭代训练**：重复上述步骤，直到模型收敛或达到预定的训练轮数。
7. **生成新视角图像**：训练完成后，可以使用训练好的MLP生成任意视角下的图像。只需输入新的3D坐标和视角方向，模型将输出对应的颜色和不透明度，从而实现新视角图像的合成。
8. **后处理**：对生成的图像进行后处理，如去噪、增强等，以提高图像质量。
