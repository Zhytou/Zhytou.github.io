<!doctype html><html lang=en>
<head>
<meta charset=utf-8>
<title>GAMES202 学习笔记 | Zhytou</title>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=generator content="Hugo 0.91.2">
<meta name=viewport content="width=device-width,initial-scale=1">
<link rel="shortcut icon" href=/favicon.ico>
<link rel=stylesheet type=text/css media=screen href=/css/normalize.css>
<link rel=stylesheet type=text/css media=screen href=/css/main.css>
<link rel=stylesheet type=text/css media=screen href=/css/all.css>
<meta property="og:title" content="GAMES202 学习笔记">
<meta property="og:description" content="1 Introdution Real-Time High Quality Rendering:
 实时性：30 frame per second（对于VR/AR，要求可能到90FPS）； 高质量：尽可能保证结果真实，即对错误容忍度低； 渲染：  4 Different Parts of Real-Time Rendering：
 阴影 全局光照 基于物理的着色 实时光线追踪  Motivation of Real-Time Rendering：
目前，计算机图形学中的技术已经支持生成一些极逼真的图像，但这些方法大多耗时过长，比如光线追踪等。因此，出现了一系列针对实时渲染的研究，它们的目的就是牺牲一小部分准确性，来获取较高质量的快速渲染。
Evolution of Real-Time Rendering：
 20年前：图形硬件（SGI/GPU）出现，大部分重点放在几何图形和纹理映射上，同时出现了一些调增强真实感的技术：阴影映射、累积缓冲区等。 10年到20年前：着色器出现（可编程图形硬件），更多复杂的图形渲染技术出现，比如：环境光、软阴影等 目前：VR/AR  Technological and Algorithmic Milestones：
 20年前：可编程图形硬件（着色器） 15年前：基于预计算的渲染方法 8-10年前：交互式光线追踪  2 Recap of CG Basics Graphics Pipeline OpenGL A Set of API：
OpenGL是一组可编程渲染管线API的封装。它的特点包括：
 跨平台； 很多替代技术，比如：DirectX和Vulkan； C风格的。  Analogy: Oil Painting：">
<meta property="og:type" content="article">
<meta property="og:url" content="https://zhytou.github.io/post/2024-8-5/games202/"><meta property="article:section" content="post">
<meta property="article:published_time" content="2024-08-05T18:26:29+08:00">
<meta property="article:modified_time" content="2024-08-05T18:26:29+08:00">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="GAMES202 学习笔记">
<meta name=twitter:description content="1 Introdution Real-Time High Quality Rendering:
 实时性：30 frame per second（对于VR/AR，要求可能到90FPS）； 高质量：尽可能保证结果真实，即对错误容忍度低； 渲染：  4 Different Parts of Real-Time Rendering：
 阴影 全局光照 基于物理的着色 实时光线追踪  Motivation of Real-Time Rendering：
目前，计算机图形学中的技术已经支持生成一些极逼真的图像，但这些方法大多耗时过长，比如光线追踪等。因此，出现了一系列针对实时渲染的研究，它们的目的就是牺牲一小部分准确性，来获取较高质量的快速渲染。
Evolution of Real-Time Rendering：
 20年前：图形硬件（SGI/GPU）出现，大部分重点放在几何图形和纹理映射上，同时出现了一些调增强真实感的技术：阴影映射、累积缓冲区等。 10年到20年前：着色器出现（可编程图形硬件），更多复杂的图形渲染技术出现，比如：环境光、软阴影等 目前：VR/AR  Technological and Algorithmic Milestones：
 20年前：可编程图形硬件（着色器） 15年前：基于预计算的渲染方法 8-10年前：交互式光线追踪  2 Recap of CG Basics Graphics Pipeline OpenGL A Set of API：
OpenGL是一组可编程渲染管线API的封装。它的特点包括：
 跨平台； 很多替代技术，比如：DirectX和Vulkan； C风格的。  Analogy: Oil Painting：">
<meta itemprop=name content="GAMES202 学习笔记">
<meta itemprop=description content="1 Introdution Real-Time High Quality Rendering:
 实时性：30 frame per second（对于VR/AR，要求可能到90FPS）； 高质量：尽可能保证结果真实，即对错误容忍度低； 渲染：  4 Different Parts of Real-Time Rendering：
 阴影 全局光照 基于物理的着色 实时光线追踪  Motivation of Real-Time Rendering：
目前，计算机图形学中的技术已经支持生成一些极逼真的图像，但这些方法大多耗时过长，比如光线追踪等。因此，出现了一系列针对实时渲染的研究，它们的目的就是牺牲一小部分准确性，来获取较高质量的快速渲染。
Evolution of Real-Time Rendering：
 20年前：图形硬件（SGI/GPU）出现，大部分重点放在几何图形和纹理映射上，同时出现了一些调增强真实感的技术：阴影映射、累积缓冲区等。 10年到20年前：着色器出现（可编程图形硬件），更多复杂的图形渲染技术出现，比如：环境光、软阴影等 目前：VR/AR  Technological and Algorithmic Milestones：
 20年前：可编程图形硬件（着色器） 15年前：基于预计算的渲染方法 8-10年前：交互式光线追踪  2 Recap of CG Basics Graphics Pipeline OpenGL A Set of API：
OpenGL是一组可编程渲染管线API的封装。它的特点包括：
 跨平台； 很多替代技术，比如：DirectX和Vulkan； C风格的。  Analogy: Oil Painting："><meta itemprop=datePublished content="2024-08-05T18:26:29+08:00">
<meta itemprop=dateModified content="2024-08-05T18:26:29+08:00">
<meta itemprop=wordCount content="540">
<meta itemprop=keywords content>
</head>
<body>
<header>
<div id=avatar>
<a href=https://zhytou.github.io/><img src=https://avatars.githubusercontent.com/u/56868292 alt=Zhytou></a>
</div>
<div id=titletext>
<h2 id=title><a href=https://zhytou.github.io/>Zhytou</a></h2>
</div>
<div id=title-description>
<p id=subtitle>May the force be with me.</p>
<div id=social>
<nav><ul>
<li><a href=https://github.com/Zhytou rel=me><i title=Github class="icons fab fa-github"></i></a></li>
<li><a><i title="Switch Dark Mode" class="dark-mode icons fas fa-moon"></i></a></li>
</ul></nav>
</div>
</div>
<div id=mainmenu>
<nav>
<ul>
<li><a href=/>Home</a></li>
<li><a href=/post>Posts</a></li>
<li><a href=/about>About</a></li>
</ul>
</nav>
</div>
</header>
<main>
<div class=post>
<article>
<div class=post-header>
<div class=meta>
<div class=date>
<span class=day>05</span>
<span class=rest>Aug 2024</span>
</div>
</div>
<div class=matter>
<h1 class=title>GAMES202 学习笔记</h1>
<p class=post-meta>
<span class=post-meta>
</span>
</p>
</div>
</div>
<div class=markdown>
<h2 id=1-introdution>1 Introdution</h2>
<p><strong>Real-Time High Quality Rendering</strong>:</p>
<ul>
<li>实时性：30 frame per second（对于VR/AR，要求可能到90FPS）；</li>
<li>高质量：尽可能保证结果真实，即对错误容忍度低；</li>
<li>渲染：</li>
</ul>
<p><strong>4 Different Parts of Real-Time Rendering</strong>：</p>
<ul>
<li>阴影</li>
<li>全局光照</li>
<li>基于物理的着色</li>
<li>实时光线追踪</li>
</ul>
<p><strong>Motivation of Real-Time Rendering</strong>：</p>
<p>目前，计算机图形学中的技术已经支持生成一些极逼真的图像，但这些方法大多耗时过长，比如光线追踪等。因此，出现了一系列针对实时渲染的研究，它们的目的就是牺牲一小部分准确性，来获取较高质量的快速渲染。</p>
<p><strong>Evolution of Real-Time Rendering</strong>：</p>
<ul>
<li>20年前：图形硬件（SGI/GPU）出现，大部分重点放在几何图形和纹理映射上，同时出现了一些调增强真实感的技术：阴影映射、累积缓冲区等。</li>
<li>10年到20年前：着色器出现（可编程图形硬件），更多复杂的图形渲染技术出现，比如：环境光、软阴影等</li>
<li>目前：VR/AR</li>
</ul>
<p><strong>Technological and Algorithmic Milestones</strong>：</p>
<ul>
<li>20年前：可编程图形硬件（着色器）</li>
<li>15年前：基于预计算的渲染方法</li>
<li>8-10年前：交互式光线追踪</li>
</ul>
<h2 id=2-recap-of-cg-basics>2 Recap of CG Basics</h2>
<h3 id=graphics-pipeline>Graphics Pipeline</h3>
<h3 id=opengl>OpenGL</h3>
<p><strong>A Set of API</strong>：</p>
<p>OpenGL是一组可编程渲染管线API的封装。它的特点包括：</p>
<ul>
<li>跨平台；</li>
<li>很多替代技术，比如：DirectX和Vulkan；</li>
<li>C风格的。</li>
</ul>
<p><strong>Analogy: Oil Painting</strong>：</p>
<p>使用OpenGL渲染的流程其实和画油画类似，包括以下几个步骤：</p>
<ul>
<li>创作油画的第一步是摆放物品/模型。类似的，渲染的第一步则是准备好待渲染模型的顶点数据，包括：顶点、法线以及纹理坐标等，并在稍后使用顶点缓存对象（Vertex Buffer Object，VBO）将其传入给GPU。</li>
<li>创作油画的第二步是摆好画架。类似的，渲染的第二步则是设置好相机位置，进行视图转换（View Transformation）。同时，还要创建顶点</li>
</ul>
<h3 id=the-rendering-equation>The Rendering Equation</h3>
<p><strong>BRDF</strong>：</p>
<p>双向反射分布函数（Bidirectional Reflectance Distribution Function，BRDF）是真实感图形学中最核心的概念之一，它描述的是物体表面将光能从任何一个入射方向反射到任何一个视点方向的反射特性，即入射光线经过某个表面反射后如何在各个出射方向上分布。</p>
<p><strong>Cook-Torrance BRDF</strong>：</p>
<p>Cook-Torrance BRDF是一种目前最流行一种BRDF反射模型，它包含漫反射和镜面反射两个部分：$f_r=k_df_{lambert}+k_sf_{cook-torrance}$。其中，$f_{lambert}=\frac\rho\pi$，而$f_{cook-torrance}=\frac{DFG}{4(\vec{w_o}<em>\vec{n})(\vec{w_i}</em>\vec{n})}$。</p>
<h2 id=3-real-time-shadows>3 Real-Time Shadows</h2>
<h3 id=shadow-mapping>Shadow Mapping</h3>
<p>阴影贴图是目前最主流的阴影生成算法。这主要得益于它算法直观，并且能够充分利用现代硬件的光栅化能力。具体来说，它的核心思路基于一个假设，即对于指定光源来说，场景中某个点是否被其照亮，取决于从光源的视角看去，这个点是否可见。</p>
<p><strong>Two-Pass Algorithmn</strong>：</p>
<p>因此，该算法被分成了两步：</p>
<ul>
<li>从光源的视角出发，绘制整个场景（平行光用正交投影，点光用透视投影），生成深度图，即所谓的阴影贴图；</li>
<li>从摄像机视角出发，重新绘制场景，并根据光源投影矩阵的逆矩阵，将世界坐标空间变换回光源的投影空间，找出对应投影空间UV坐标以及投影空间内的深度d。</li>
</ul>
<p>此时，就可以使用光源投影空间的UV坐标和阴影贴图，得到深度z。比较深度z和深度d，若d>z，则当前位置被遮挡，处于阴影内；反之，则未被遮挡。</p>
<p>可见，阴影贴图是一个完全在图像空间中的算法。它的优点是一旦贴图已经生成，则其就可以作为场景中的几何表示(场景中所有位置在光源处的深度)，而不用再去获取场景中的其他信息。而缺点则是算法会产生自遮挡和走样现象。</p>
<p><strong>Simple Implementation with GLSL</strong>：</p>
<p>了解了阴影贴图的流程之后，我们可以简单实现它。比如：Phase 1中预生成阴影纹理的片元着色器如下。</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-glsl data-lang=glsl><span style=color:#579>#ifdef GL_ES</span>
<span style=color:#080;font-weight:700>precision</span> <span style=color:#080;font-weight:700>mediump</span> <span style=color:#080;font-weight:700>float</span>;
<span style=color:#579>#endif</span>

<span style=color:#080;font-weight:700>uniform</span> <span style=color:#080;font-weight:700>vec3</span> uLightPos;
<span style=color:#080;font-weight:700>uniform</span> <span style=color:#080;font-weight:700>vec3</span> uCameraPos;

<span style=color:#080;font-weight:700>varying</span> <span style=color:#080;font-weight:700>highp</span> <span style=color:#080;font-weight:700>vec3</span> vNormal;
<span style=color:#080;font-weight:700>varying</span> <span style=color:#080;font-weight:700>highp</span> <span style=color:#080;font-weight:700>vec2</span> vTextureCoord;

<span style=color:#080;font-weight:700>vec4</span> pack (<span style=color:#080;font-weight:700>float</span> depth) {
    <span style=color:#888>// 使用rgba 4字节共32位来存储z值,1个字节精度为1/256</span>
    <span style=color:#080;font-weight:700>const</span> <span style=color:#080;font-weight:700>vec4</span> bitShift <span style=color:#333>=</span> <span style=color:#080;font-weight:700>vec4</span>(<span style=color:#60e;font-weight:700>1.0</span>, <span style=color:#60e;font-weight:700>256.0</span>, <span style=color:#60e;font-weight:700>256.0</span> <span style=color:#333>*</span> <span style=color:#60e;font-weight:700>256.0</span>, <span style=color:#60e;font-weight:700>256.0</span> <span style=color:#333>*</span> <span style=color:#60e;font-weight:700>256.0</span> <span style=color:#333>*</span> <span style=color:#60e;font-weight:700>256.0</span>);
    <span style=color:#080;font-weight:700>const</span> <span style=color:#080;font-weight:700>vec4</span> bitMask <span style=color:#333>=</span> <span style=color:#080;font-weight:700>vec4</span>(<span style=color:#60e;font-weight:700>1.0</span><span style=color:#333>/</span><span style=color:#60e;font-weight:700>256.0</span>, <span style=color:#60e;font-weight:700>1.0</span><span style=color:#333>/</span><span style=color:#60e;font-weight:700>256.0</span>, <span style=color:#60e;font-weight:700>1.0</span><span style=color:#333>/</span><span style=color:#60e;font-weight:700>256.0</span>, <span style=color:#60e;font-weight:700>0.0</span>);
    <span style=color:#888>// gl_FragCoord:片元的坐标,fract():返回数值的小数部分</span>
    <span style=color:#080;font-weight:700>vec4</span> rgbaDepth <span style=color:#333>=</span> fract(depth <span style=color:#333>*</span> bitShift); <span style=color:#888>//计算每个点的z值</span>
    <span style=color:#888>// Cut off the value which do not fit in 8 bits</span>
    rgbaDepth <span style=color:#333>-=</span> rgbaDepth.gbaa <span style=color:#333>*</span> bitMask; 
    <span style=color:#080;font-weight:700>return</span> rgbaDepth;
}

<span style=color:#080;font-weight:700>void</span> main(){
  gl_FragColor <span style=color:#333>=</span> pack(gl_FragCoord.z);
}
</code></pre></div><p>Phase 2中显示的片元着色器如下：</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-glsl data-lang=glsl><span style=color:#080;font-weight:700>float</span> unpack(<span style=color:#080;font-weight:700>vec4</span> rgbaDepth) {
  <span style=color:#080;font-weight:700>const</span> <span style=color:#080;font-weight:700>vec4</span> bitShift <span style=color:#333>=</span> <span style=color:#080;font-weight:700>vec4</span>(<span style=color:#60e;font-weight:700>1.0</span>, <span style=color:#60e;font-weight:700>1.0</span><span style=color:#333>/</span><span style=color:#60e;font-weight:700>256.0</span>, <span style=color:#60e;font-weight:700>1.0</span><span style=color:#333>/</span>(<span style=color:#60e;font-weight:700>256.0</span><span style=color:#333>*</span><span style=color:#60e;font-weight:700>256.0</span>), <span style=color:#60e;font-weight:700>1.0</span><span style=color:#333>/</span>(<span style=color:#60e;font-weight:700>256.0</span><span style=color:#333>*</span><span style=color:#60e;font-weight:700>256.0</span><span style=color:#333>*</span><span style=color:#60e;font-weight:700>256.0</span>));
  <span style=color:#080;font-weight:700>return</span> dot(rgbaDepth, bitShift);
}

<span style=color:#080;font-weight:700>float</span> useShadowMap(<span style=color:#080;font-weight:700>sampler2D</span> shadowMap, <span style=color:#080;font-weight:700>vec4</span> shadowCoord){
  <span style=color:#080;font-weight:700>float</span> d <span style=color:#333>=</span> unpack(texture2D(shadowMap, shadowCoord.xy));
  <span style=color:#080;font-weight:700>if</span> (shadowCoord.z <span style=color:#333>&gt;</span> d <span style=color:#333>+</span> EPS) {
    <span style=color:#080;font-weight:700>return</span> <span style=color:#60e;font-weight:700>0.0</span>;
  } <span style=color:#080;font-weight:700>else</span> {
    <span style=color:#080;font-weight:700>return</span> <span style=color:#60e;font-weight:700>1.0</span>;
  }
}

<span style=color:#080;font-weight:700>void</span> main(<span style=color:#080;font-weight:700>void</span>) {

  <span style=color:#888>//vPositionFromLight为光源空间下投影的裁剪坐标，除以w结果为NDC坐标</span>
  <span style=color:#080;font-weight:700>vec3</span> shadowCoord <span style=color:#333>=</span> vPositionFromLight.xyz <span style=color:#333>/</span> vPositionFromLight.w;
  <span style=color:#888>//把[-1,1]的NDC坐标转换为[0,1]的坐标</span>
  shadowCoord <span style=color:#333>=</span> (shadowCoord <span style=color:#333>+</span> <span style=color:#60e;font-weight:700>1.0</span>) <span style=color:#333>/</span> <span style=color:#60e;font-weight:700>2.0</span>;

  <span style=color:#888>// 计算是否为阴影（因为是硬阴影，所有返回值仅为0或1）</span>
  <span style=color:#080;font-weight:700>float</span> visibility <span style=color:#333>=</span> useShadowMap(uShadowMap, <span style=color:#080;font-weight:700>vec4</span>(shadowCoord, <span style=color:#60e;font-weight:700>1.0</span>));
  <span style=color:#888>// 计算颜色</span>
  <span style=color:#080;font-weight:700>vec3</span> phongColor <span style=color:#333>=</span> blinnPhong();

  gl_FragColor <span style=color:#333>=</span> <span style=color:#080;font-weight:700>vec4</span>(phongColor <span style=color:#333>*</span> visibility, <span style=color:#60e;font-weight:700>1.0</span>);
}
</code></pre></div><p><strong>Issues in Shadow Mapping</strong>：</p>
<p>阴影失真（Shadow Acne）是阴影贴图中最容易出现的问题。它表现为在阴影区域出现间隔的条纹，如下图所示。</p>
<p><figure>
<img src=https://i-blog.csdnimg.cn/blog_migrate/c4d0c52217b34561520e3340a93f7200.png alt=阴影失真>
</figure></p>
<p>出现这种现象的原因在于ShadowMap中的每个texel只能记录一个深度值，但一个像素内的不同位置可能会有不同的深度值（即，试图用离散的纹理去记录连续的信息）。因此，当实际场景的深度值大于ShadowMap上记录的深度值时，就会出现Shadow Acne现象。</p>
<p>一个简单通用的解决方案是在比较前给d加上一个固定偏移。但是若偏移选取过大，又会产生所谓的阴影悬空（Peter-Panning）问题，如下图所示。</p>
<p><figure>
<img src=https://pic2.zhimg.com/80/v2-8b7a421a28ac57a3b779cb824f1e0cb9_720w.webp alt=阴影悬空>
</figure></p>
<p>改进的方法则是添加自适应偏移的方案，即基于斜率去计算当前深度要加的偏移（Slope Scale Depth Bias）。</p>
<p>另外，阴影走样（Shadow Aliasing）也是阴影贴图中容易出现的问题。比如</p>
<p><figure>
<img src=https://i-blog.csdnimg.cn/blog_migrate/08e1b652b0eb13a489399f583989c68c.png alt=阴影走样>
</figure></p>
<p>其原因则是阴影贴图是一个大小不足，造成多个片段对应一个纹理像素。工业界的解决办法是，不同位置采用不同分辨率的shadow map，或者是动态分辨率之类的技术，也可以直接用PCF生成软阴影。</p>
<p>除此之外，阴影贴图还存在纹理利用不足的问题。因为相机和光源视角不同，所以从光源视角光栅化后的每个像素投影到屏幕空间后，对应的区域大小也不相同，进而引发靠近相机位置的阴影贴图精度不够，而远离相机位置的阴影贴图精度又过高的问题。改善这种利用率不足的方法包括：级联阴影贴图和Sample Distribution Shadow Map。</p>
<h3 id=percentage-closer-filtering>Percentage Closer Filtering</h3>
<p>百分比渐进滤波（Percentage-Closer Filtering，PCF）是一种滤波工具。它可以改善阴影的平滑度和真实感，减少硬边缘和锯齿效果。</p>
<p>PCF并非在直接在最后生成的结果上做模糊，或是对Phase1计算得到阴影贴图进行模糊，而是在做阴影判断时进行滤波操作从而生成更合理的visibility。因为已经出现走样即高频重叠后，再去进行模糊是无法消除重叠的；而对阴影贴图进行模糊并不能改善visibility返回值非0即1的情况。</p>
<p>具体来说，其原理就是计算visibility时，在原阴影贴图坐标一定范围中，选择若干随机点；将这些点的深度值，和原点的深度值作比较，最后将其加和取平均即可。其在GLSL中的实现如下：</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-GLSL data-lang=GLSL><span style=color:#080;font-weight:700>float</span> PCF(<span style=color:#080;font-weight:700>sampler2D</span> shadowMap, <span style=color:#080;font-weight:700>vec4</span> coords, <span style=color:#080;font-weight:700>float</span> filterSize) {
  <span style=color:#080;font-weight:700>float</span> visibility <span style=color:#333>=</span> <span style=color:#60e;font-weight:700>0.0</span>;

  poissonDiskSamples(coords.xy);
  <span style=color:#080;font-weight:700>for</span> (<span style=color:#080;font-weight:700>int</span> i <span style=color:#333>=</span> <span style=color:#40e;font-weight:700>0</span>; i <span style=color:#333>&lt;</span> NUM_SAMPLES; i<span style=color:#333>++</span>) {
    <span style=color:#888>// 偏移量 = 0到1随机变量 * 归一化后的采样半径</span>
    <span style=color:#080;font-weight:700>vec4</span> offset <span style=color:#333>=</span> <span style=color:#080;font-weight:700>vec4</span>(poissonDisk[i], <span style=color:#40e;font-weight:700>0</span>, <span style=color:#40e;font-weight:700>0</span>) <span style=color:#333>*</span> filterSize;
    <span style=color:#888>// 采样点位置 = 实际位置 + 偏移量</span>
    <span style=color:#080;font-weight:700>float</span> d <span style=color:#333>=</span> useShadowMap(shadowMap, coords <span style=color:#333>+</span> offset);
    <span style=color:#080;font-weight:700>if</span> (d <span style=color:#333>+</span> EPS <span style=color:#333>&gt;</span> coords.z) {
      visibility <span style=color:#333>=</span> visibility <span style=color:#333>+</span> <span style=color:#60e;font-weight:700>1.0</span>;
    }
  }
  <span style=color:#888>// 取平均</span>
  <span style=color:#080;font-weight:700>return</span> visibility <span style=color:#333>/</span> <span style=color:#080;font-weight:700>float</span>(NUM_SAMPLES);
}
</code></pre></div><h3 id=percentage-closer-soft-shadow>Percentage Closer Soft Shadow</h3>
<p>如下图所示，在真实世界中，笔尖的阴影十分锐利，而笔杆的阴影会软一些。</p>
<p><figure>
<img src=https://i-blog.csdnimg.cn/blog_migrate/99b100153b711cf71511864ea50e5462.png alt=钢笔的阴影>
</figure></p>
<p>由此，我们可以得出结论：</p>
<ul>
<li>承载阴影的物体表面点与阴影产生物的距离越小，阴影越硬。</li>
<li>阴影的软硬与光源距离无关，与遮挡物距离有关</li>
</ul>
<p><figure>
<img src=https://i-blog.csdnimg.cn/blog_migrate/7c25e9e78dca72b3a5708523fcd85c50.png alt=软阴影面积变化示意图>
</figure></p>
<p>进一步，我们可以根据相似三角形定理从上述示意图中推导出一个公式，这也是PCSS的核心。</p>
<p>$$
\frac{W_{Penumbra}}{W_{Light}}=\frac{d_{Receiver}-d_{Blocker}}{d_{Blocker}}
$$</p>
<p>其中，$W_{Penumbra}$表示软阴影大小；$W_{Light}$表示光源大小；$d_{Receiver}$表示光源到片元的距离；$d_{Blocker}$表示光源到遮挡物的距离。</p>
<p>百分比渐进软阴影（Percentage Closer Soft Shadow, PCSS）技术是对PCF的进一步改进，它能实现更逼真的阴影效果，即阴影的软硬会随承载阴影的物体表面与阴影产生物的距离变化。换句话说，它能根据上述原理针对不同片元生成自适应软阴影大小，也即上述PCF实现中使用的采样范围。其GLSL实现如下：</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-GLSL data-lang=GLSL><span style=color:#080;font-weight:700>float</span> findBlocker(<span style=color:#080;font-weight:700>sampler2D</span> shadowMap, <span style=color:#080;font-weight:700>vec2</span> uv, <span style=color:#080;font-weight:700>float</span> zReceiver, <span style=color:#080;font-weight:700>float</span> searchRange) {
  <span style=color:#080;font-weight:700>float</span> depthSum <span style=color:#333>=</span> <span style=color:#60e;font-weight:700>0.0</span>;
  <span style=color:#080;font-weight:700>int</span> blockerNum <span style=color:#333>=</span> <span style=color:#40e;font-weight:700>0</span>;

  poissonDiskSamples(uv);
  <span style=color:#080;font-weight:700>for</span> (<span style=color:#080;font-weight:700>int</span> i <span style=color:#333>=</span> <span style=color:#40e;font-weight:700>0</span>; i <span style=color:#333>&lt;</span> NUM_SAMPLES; i<span style=color:#333>++</span>) {
    <span style=color:#080;font-weight:700>float</span> d <span style=color:#333>=</span> unpack(texture2D(shadowMap, uv <span style=color:#333>+</span> poissonDisk[i] <span style=color:#333>*</span> searchRange));
    <span style=color:#080;font-weight:700>if</span> (d <span style=color:#333>+</span> EPS <span style=color:#333>&lt;</span> zReceiver) {
      depthSum <span style=color:#333>=</span> depthSum <span style=color:#333>+</span> d;
      blockerNum <span style=color:#333>=</span> blockerNum <span style=color:#333>+</span> <span style=color:#00d;font-weight:700>1</span>;
    }
  }

  <span style=color:#080;font-weight:700>if</span> (blockerNum <span style=color:#333>==</span> <span style=color:#40e;font-weight:700>0</span>) {
    <span style=color:#080;font-weight:700>return</span> <span style=color:#60e;font-weight:700>0.0</span>;
  }

  <span style=color:#080;font-weight:700>return</span> depthSum <span style=color:#333>/</span> <span style=color:#080;font-weight:700>float</span>(blockerNum);
}

<span style=color:#080;font-weight:700>float</span> PCSS(<span style=color:#080;font-weight:700>sampler2D</span> shadowMap, <span style=color:#080;font-weight:700>vec4</span> coords, <span style=color:#080;font-weight:700>float</span> searchRange){

  <span style=color:#888>// STEP 1: avgblocker depth</span>
  <span style=color:#080;font-weight:700>float</span> avgDepth <span style=color:#333>=</span> findBlocker(shadowMap, coords.xy, coords.z, searchRange);

  <span style=color:#888>// STEP 2: penumbra size</span>
  <span style=color:#080;font-weight:700>if</span> (avgDepth <span style=color:#333>==</span> <span style=color:#60e;font-weight:700>0.0</span>) {
    <span style=color:#080;font-weight:700>return</span> <span style=color:#60e;font-weight:700>1.0</span>;
  }
  <span style=color:#080;font-weight:700>float</span> penumbraSize <span style=color:#333>=</span> (coords.z <span style=color:#333>-</span> avgDepth) <span style=color:#333>/</span> avgDepth <span style=color:#333>*</span> LIGHT_SIZE;

  <span style=color:#888>// STEP 3: filtering</span>
  <span style=color:#080;font-weight:700>float</span> visibility <span style=color:#333>=</span> PCF(shadowMap, coords, penumbraSize);

  <span style=color:#080;font-weight:700>return</span> visibility;
}
</code></pre></div><h3 id=variance-soft-shadow-mapping>Variance Soft Shadow Mapping</h3>
<p>PCSS、PCF 的算法都需要多重采样，尤其 PCSS 需要两个多重采样（第一步的Blocker Search和第三步的PCF），这使得算法速度较慢。</p>
<p>为了避免多重采样的计算，Variance Soft Shadow Mapping（VSSM）假定一定范围内的深度的分布符合正态分布（Normal Distribution） ，那么只要知道该段范围的均值E 、方差Var，就能先得到该范围的概率密度函数PDF。进而通过该概率密度函数的积分——累计分布函数CDF快速计算出该范围中有多少比例大于某个指定深度。</p>
<h3 id=cascaded-shadow-mapping>Cascaded Shadow Mapping</h3>
<h2 id=4-real-time-environment-mapping>4 Real-Time Environment Mapping</h2>
<h3 id=recap-image-based-lighting>Recap: Image-Based Lighting</h3>
<p>基于图像的光照(Image Based Lighting, IBL)</p>
<h3 id=split-sum-approximation>Split Sum Approximation</h3>
</div>
</div>
</article>
</div>
</main>
<footer>
© Copyright <a href=https://github.com/Zhytou>Zhytou</a> | <a href=https://github.com/dataCobra/hugo-vitae>Vitae</a> theme for <a href=https://gohugo.io>Hugo</a>
</footer><script src=/js/dark-mode.js></script>
</body>
</html>